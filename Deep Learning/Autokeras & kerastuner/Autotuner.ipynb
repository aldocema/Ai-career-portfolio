{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab2373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primeramente se descarga la base de datos que será la de perros y gatos\n",
    "#import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from matplotlib import image\n",
    "\n",
    "files=zipfile.ZipFile('cats_and_dogs_small.zip','r')\n",
    "files.extractall('')\n",
    "\n",
    "x_dog=[]\n",
    "x_cat=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e596e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "x_size=150\n",
    "y_size=150\n",
    "\n",
    "for name in files.namelist():\n",
    "    if '/dogs/' in name and '.jpg' in name:\n",
    "        a=cv2.imread(name)\n",
    "        a=cv2.resize(a,(x_size,y_size)) # Dimensión de la imagen\n",
    "        img = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        #img2=img.resize(200,200) # Mobilenet (224,224,3)\n",
    "        x_dog.append(img)\n",
    "        \n",
    "    elif '/cats/' in name and '.jpg' in name:\n",
    "        a=cv2.imread(name)\n",
    "        a=cv2.resize(a,(x_size,y_size)) # Dimensión de la imagen\n",
    "        img = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        x_cat.append(img)\n",
    "print(len(x_dog),len(x_cat))\n",
    "x_dog=np.stack(x_dog,axis=0)\n",
    "x_cat=np.stack(x_cat,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbc7ed",
   "metadata": {},
   "source": [
    "# One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030031c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2000, 150, 150, 3)\n",
      "<class 'numpy.ndarray'> (2000, 150, 150, 3)\n",
      "4 (4000, 150, 150, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0. 1.]\n",
      "<class 'numpy.ndarray'> (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_dog),x_dog.shape)\n",
    "print(type(x_cat),x_cat.shape)\n",
    "x_dog=x_dog.astype('float32')\n",
    "x,y,z,w=x_dog.shape\n",
    "y_dog=np.zeros((x,1),dtype=int)\n",
    "x_cat=x_cat.astype('float32')\n",
    "x,y,z,w=x_cat.shape\n",
    "y_cat=np.ones((x,1),dtype=int)\n",
    "#x_dog=(x_dog/127.5)-1#x_dog/=255\n",
    "#x_cat=(x_cat/127.5)-1#x_cat/=255\n",
    "## Conjunto combinado de perros y gatos\n",
    "x_comb=np.vstack((x_dog,x_cat))\n",
    "y_comb=np.vstack((y_dog,y_cat))\n",
    "print(x_comb.ndim,x_comb.shape)\n",
    "#print(y_dog)\n",
    "\n",
    "\n",
    "### ONE HOT\n",
    "from keras.utils import to_categorical\n",
    "y_dog_oh=to_categorical(y_dog,y_dog.max()+2)\n",
    "y_cat_oh=to_categorical(y_cat,y_cat.max()+1)\n",
    "print(y_comb[3455])\n",
    "y_comb_oh=to_categorical(y_comb,y_comb.max()+1)\n",
    "print(y_comb_oh[3455])\n",
    "print(type(y_comb_oh),y_comb_oh.shape)\n",
    "#print(y_cat_oh.shape)\n",
    "#print(y_dog_oh.shape)\n",
    "#print(y_dog_oh)\n",
    "#print(y_cat_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e494d18",
   "metadata": {},
   "source": [
    "# División de datos 60 20 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045eb8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n"
     ]
    }
   ],
   "source": [
    "xx,yy,ww,zz=x_cat.shape\n",
    "x_train=np.vstack((x_cat[:int(xx*0.6),:,:,:],x_dog[:int(xx*0.6),:,:,:]))\n",
    "y_train=np.vstack((y_cat[:int(xx*0.6),:],y_dog[:int(xx*0.6),:]))\n",
    "x_val=np.vstack((x_cat[int(xx*0.6):int(xx*0.8),:,:,:],x_dog[int(xx*0.6):int(xx*0.8),:,:,:]))\n",
    "y_val=np.vstack((y_cat[int(xx*0.6):int(xx*0.8),:],y_dog[int(xx*0.6):int(xx*0.8),:]))\n",
    "x_test=np.vstack((x_cat[int(xx*0.8):,:,:,:],x_dog[int(xx*0.8):,:,:,:]))\n",
    "y_test=np.vstack((y_cat[int(xx*0.8):,:],y_dog[int(xx*0.8):,:]))\n",
    "\n",
    "print(x_test.min(),x_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c250180",
   "metadata": {},
   "source": [
    "# Autokeras Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268853ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 10m 48s]\n",
      "val_loss: 0.0\n",
      "\n",
      "Best val_loss So Far: 0.0\n",
      "Total elapsed time: 00h 12m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "75/75 [==============================] - 258s 3s/step - loss: 0.5856 - accuracy: 0.9517\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 251s 3s/step - loss: 1.4074 - accuracy: 0.8800\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 263s 4s/step - loss: 2.0641 - accuracy: 0.7742\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2dafee580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "clf=ak.ImageClassifier(overwrite=True,max_trials=2)\n",
    "clf.fit(x_train,y_train,epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6244995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-3._random_generator._generator._state_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-3._random_generator._generator._state_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-4._random_generator._generator._state_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer-4._random_generator._generator._state_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 27s 1s/step\n",
      "25/25 [==============================] - 26s 1s/step\n"
     ]
    }
   ],
   "source": [
    "## predicciones \n",
    "pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563697f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactitud de la prueba=  50.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=np.argmax(pred,axis=1)\n",
    "\n",
    "exactitud_test=0\n",
    "for a in range(len(pred)):\n",
    "    if pred[a]==y_test[a]:\n",
    "        exactitud_test+=1\n",
    "print('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60457761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Se propone una red neuronal ResNet50\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\"\"\"\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint =  ModelCheckpoint('resnet50.h', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)    \n",
    "x_train_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_train))\n",
    "x_val_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_val))\n",
    "x_test_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_test))\n",
    "model = ResNet50(input_shape=(x_size,y_size,3),weights=None,include_top=False) ## Colocar otro top\n",
    "for i in range(165):\n",
    "    model.layers[i].trainable=False\n",
    "#model.summary()\n",
    "sal=model.output\n",
    "sal=Flatten()(sal)\n",
    "sal=Dense(502,activation='selu')(sal)\n",
    "sal=Dropout(0.26)(sal)\n",
    "sal = Dense(256, activation='relu')(sal)\n",
    "sal=Dense(100,activation='selu')(sal)\n",
    "sal=Dense(50,activation='relu')(sal)\n",
    "sal = Dense(2, activation='softmax')(sal)\n",
    "#Se unen la CNN y el top\n",
    "resnet50_custom=Model(inputs=model.input, outputs=sal)\n",
    "resnet50_custom.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\"\"\"\n",
    "\n",
    "x_train_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_train))\n",
    "x_val_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_val))\n",
    "x_test_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_test))\n",
    "\n",
    "def model_builder(hp):\n",
    "\n",
    "    model = ResNet50(input_shape=(x_size,y_size,3),weights=None,include_top=False) ## Colocar otro top\n",
    "    for i in range(165):\n",
    "        model.layers[i].trainable=False    \n",
    "    sal=model.output\n",
    "    sal=Flatten()(sal)\n",
    "    sal=Dense(502,activation='selu')(sal)\n",
    "    sal=Dropout(0.26)(sal)\n",
    "    sal = Dense(256, activation='relu')(sal)\n",
    "    sal=Dense(100,activation='selu')(sal)\n",
    "    sal=Dense(50,activation='relu')(sal)\n",
    "    sal = Dense(2, activation='softmax')(sal)\n",
    "    #Se unen la CNN y el top\n",
    "    resnet50_custom=Model(inputs=model.input, outputs=sal)\n",
    "    resnet50_custom.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f0dde",
   "metadata": {},
   "source": [
    "# Se importa la librería keras_tuner\n",
    "\n",
    "posteriormente se aplica el tuner, se eligío el Hyperband pues tiene las siguientes caracteristicas:\n",
    "\n",
    "El algoritmo de sintonización Hyperband utiliza la asignación de recursos adaptable y la detención anticipada para converger rápidamente en un modelo de alto rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb37777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt \n",
    "\n",
    "tuner=kt.Hyperband(model_builder,objective='val_accuracy',max_epochs=5,factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa86b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace3bd6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19648\\1641816710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_acc_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_acc_per_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3158\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   3161\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95541290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
