{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2662c19c",
   "metadata": {},
   "source": [
    "# Uso de archivo zip \n",
    "uso de zip para descomprimir y obtener los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bd253b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from matplotlib import image\n",
    "\n",
    "files=zipfile.ZipFile('cats_and_dogs_small.zip','r')\n",
    "files.extractall('')\n",
    "\n",
    "x_dog=[]\n",
    "x_cat=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc199af4",
   "metadata": {},
   "source": [
    "# Filtrado de datos en gatos y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31717db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "x_size=150\n",
    "y_size=150\n",
    "\n",
    "for name in files.namelist():\n",
    "    if '/dogs/' in name and '.jpg' in name:\n",
    "        a=cv2.imread(name)\n",
    "        a=cv2.resize(a,(x_size,y_size)) # Dimensi贸n de la imagen\n",
    "        img = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        #img2=img.resize(200,200) # Mobilenet (224,224,3)\n",
    "        x_dog.append(img)\n",
    "        \n",
    "    elif '/cats/' in name and '.jpg' in name:\n",
    "        a=cv2.imread(name)\n",
    "        a=cv2.resize(a,(x_size,y_size)) # Dimensi贸n de la imagen\n",
    "        img = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        x_cat.append(img)\n",
    "print(len(x_dog),len(x_cat))\n",
    "x_dog=np.stack(x_dog,axis=0)\n",
    "x_cat=np.stack(x_cat,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37d98ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na=cv2.imread(name)\\na=cv2.resize(a,(200,200))\\nprint(a.shape)\\nimg = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\\nprint(img.shape)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a=cv2.imread(name)\n",
    "a=cv2.resize(a,(200,200))\n",
    "print(a.shape)\n",
    "img = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d01f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e13433",
   "metadata": {},
   "source": [
    "# Normalizaci贸n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33e6f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2000, 150, 150, 3)\n",
      "<class 'numpy.ndarray'> (2000, 150, 150, 3)\n",
      "4 (4000, 150, 150, 3)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(x_dog),x_dog.shape)\n",
    "print(type(x_cat),x_cat.shape)\n",
    "x_dog=x_dog.astype('float32')\n",
    "x,y,z,w=x_dog.shape\n",
    "y_dog=np.zeros((x,1),dtype=int)\n",
    "x_cat=x_cat.astype('float32')\n",
    "x,y,z,w=x_cat.shape\n",
    "y_cat=np.ones((x,1),dtype=int)\n",
    "#x_dog=(x_dog/127.5)-1#x_dog/=255\n",
    "#x_cat=(x_cat/127.5)-1#x_cat/=255\n",
    "## Conjunto combinado de perros y gatos\n",
    "x_comb=np.vstack((x_dog,x_cat))\n",
    "y_comb=np.vstack((y_dog,y_cat))\n",
    "print(x_comb.ndim,x_comb.shape)\n",
    "print(y_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3256fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0. 1.]\n",
      "<class 'numpy.ndarray'> (4000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ONE HOT\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_dog_oh=to_categorical(y_dog,y_dog.max()+2)\n",
    "y_cat_oh=to_categorical(y_cat,y_cat.max()+1)\n",
    "print(y_comb[3455])\n",
    "y_comb_oh=to_categorical(y_comb,y_comb.max()+1)\n",
    "print(y_comb_oh[3455])\n",
    "print(type(y_comb_oh),y_comb_oh.shape)\n",
    "print(y_cat_oh.shape)\n",
    "print(y_dog_oh.shape)\n",
    "print(y_dog_oh)\n",
    "#print(y_cat_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84dd159",
   "metadata": {},
   "source": [
    "# Divisi贸n 60 20 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71b75fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "xx,yy,ww,zz=x_cat.shape\n",
    "x_train=np.vstack((x_cat[:int(xx*0.6),:,:,:],x_dog[:int(xx*0.6),:,:,:]))\n",
    "y_train=np.vstack((y_cat_oh[:int(xx*0.6),:],y_dog_oh[:int(xx*0.6),:]))\n",
    "x_val=np.vstack((x_cat[int(xx*0.6):int(xx*0.8),:,:,:],x_dog[int(xx*0.6):int(xx*0.8),:,:,:]))\n",
    "y_val=np.vstack((y_cat_oh[int(xx*0.6):int(xx*0.8),:],y_dog_oh[int(xx*0.6):int(xx*0.8),:]))\n",
    "x_test=np.vstack((x_cat[int(xx*0.8):,:,:,:],x_dog[int(xx*0.8):,:,:,:]))\n",
    "y_test=np.vstack((y_cat_oh[int(xx*0.8):,:],y_dog_oh[int(xx*0.8):,:]))\n",
    "\n",
    "print(x_test.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc761a1c",
   "metadata": {},
   "source": [
    "# Red LeNet5\n",
    "\n",
    "## preprocessing y deshabilitar entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfac30d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\nfrom keras.models import Model, load_model\\n#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense,Flatten,Dropout,Input\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\\n\\nlr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\\ncheckpoint =  ModelCheckpoint('vgg16_finetune.h5', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\\nearlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True) \\n\\nx_train=np.vstack((x_cat[:int(xx*0.6),:,:,1:2],x_dog[:int(xx*0.6),:,:,1:2]))\\ny_train=np.vstack((y_cat_oh[:int(xx*0.6),:],y_dog_oh[:int(xx*0.6),:]))\\nx_val=np.vstack((x_cat[int(xx*0.6):int(xx*0.8),:,:,1:2],x_dog[int(xx*0.6):int(xx*0.8),:,:,1:2]))\\ny_val=np.vstack((y_cat_oh[int(xx*0.6):int(xx*0.8),:],y_dog_oh[int(xx*0.6):int(xx*0.8),:]))\\nx_test=np.vstack((x_cat[int(xx*0.8):,:,:,1:2],x_dog[int(xx*0.8):,:,:,1:2]))\\ny_test=np.vstack((y_cat_oh[int(xx*0.8):,:],y_dog_oh[int(xx*0.8):,:]))\\n\\n\\nmodel=Sequential()\\nmodel.add(tf.keras.layers.Conv2D(6,(5,5),input_shape=(x_size,y_size,1),activation='tanh',padding='valid',strides=1)) #C1\\n\\nmodel.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2))) #S2\\n\\nmodel.add(tf.keras.layers.Conv2D(16,(5,5),activation='tanh',padding='valid',strides=1)) #c3\\n\\nmodel.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2))) #s4\\nmodel.add(tf.keras.layers.Flatten())\\n\\nmodel.add(Dense(120,activation='tanh')) #c5\\nmodel.add(Dense(84,activation='tanh')) #c6\\n\\nfrom keras.layers import Layer\\nfrom keras import backend as K\\n\\nclass RBFLayer(Layer):\\n    def __init__(self, units, gamma, **kwargs):\\n        super(RBFLayer, self).__init__(**kwargs)\\n        self.units = units\\n        self.gamma = K.cast_to_floatx(gamma)\\n\\n    def build(self, input_shape):\\n        self.mu = self.add_weight(name='mu',\\n                                  shape=(int(input_shape[1]), self.units),\\n                                  initializer='uniform',\\n                                  trainable=True)\\n        super(RBFLayer, self).build(input_shape)\\n\\n    def call(self, inputs):\\n        diff = K.expand_dims(inputs) - self.mu\\n        l2 = K.sum(K.pow(diff,2), axis=1)\\n        res = K.exp(-1 * self.gamma * l2)\\n        return res\\n\\n    def compute_output_shape(self, input_shape):\\n        return (input_shape[0], self.units)\\n    \\nmodel.add(RBFLayer(2,0.5)) #c7\\n\\nmodel.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=0.25),metrics=['accuracy'])\\nmodel.fit(x_train,y_train,verbose=1, batch_size=64,epochs=100,validation_data=(x_val,y_val))\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint =  ModelCheckpoint('vgg16_finetune.h5', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True) \n",
    "\n",
    "x_train=np.vstack((x_cat[:int(xx*0.6),:,:,1:2],x_dog[:int(xx*0.6),:,:,1:2]))\n",
    "y_train=np.vstack((y_cat_oh[:int(xx*0.6),:],y_dog_oh[:int(xx*0.6),:]))\n",
    "x_val=np.vstack((x_cat[int(xx*0.6):int(xx*0.8),:,:,1:2],x_dog[int(xx*0.6):int(xx*0.8),:,:,1:2]))\n",
    "y_val=np.vstack((y_cat_oh[int(xx*0.6):int(xx*0.8),:],y_dog_oh[int(xx*0.6):int(xx*0.8),:]))\n",
    "x_test=np.vstack((x_cat[int(xx*0.8):,:,:,1:2],x_dog[int(xx*0.8):,:,:,1:2]))\n",
    "y_test=np.vstack((y_cat_oh[int(xx*0.8):,:],y_dog_oh[int(xx*0.8):,:]))\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(6,(5,5),input_shape=(x_size,y_size,1),activation='tanh',padding='valid',strides=1)) #C1\n",
    "\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2))) #S2\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(16,(5,5),activation='tanh',padding='valid',strides=1)) #c3\n",
    "\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2))) #s4\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(Dense(120,activation='tanh')) #c5\n",
    "model.add(Dense(84,activation='tanh')) #c6\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1)\n",
    "        res = K.exp(-1 * self.gamma * l2)\n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "    \n",
    "model.add(RBFLayer(2,0.5)) #c7\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(learning_rate=0.25),metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,verbose=1, batch_size=64,epochs=100,validation_data=(x_val,y_val))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83242011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npred=model.predict(x_test)\\npred=np.argmax(pred,axis=1)\\ny1=np.argmax(y_test,axis=1)\\n\\n#label=np.argmax(yp_oh)\\nexactitud_test=0\\nfor a in range(len(pred)):\\n    if pred[a]==y1[a]:\\n        exactitud_test+=1\\nprint('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pred=model.predict(x_test)\n",
    "pred=np.argmax(pred,axis=1)\n",
    "y1=np.argmax(y_test,axis=1)\n",
    "\n",
    "#label=np.argmax(yp_oh)\n",
    "exactitud_test=0\n",
    "for a in range(len(pred)):\n",
    "    if pred[a]==y1[a]:\n",
    "        exactitud_test+=1\n",
    "print('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a085bcc",
   "metadata": {},
   "source": [
    "   # Red ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b909857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 57s 1s/step - loss: 1.3805 - accuracy: 0.4900 - val_loss: 0.7172 - val_accuracy: 0.5075\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50750, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.7683 - accuracy: 0.5046 - val_loss: 0.7103 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.50750 to 0.51000, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.7437 - accuracy: 0.5113 - val_loss: 0.7002 - val_accuracy: 0.5013\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.51000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.7219 - accuracy: 0.5258 - val_loss: 0.6868 - val_accuracy: 0.5512\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.51000 to 0.55125, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.7222 - accuracy: 0.5179 - val_loss: 0.6867 - val_accuracy: 0.5375\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.55125\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.7098 - accuracy: 0.5192 - val_loss: 0.6827 - val_accuracy: 0.5437\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.55125\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.7025 - accuracy: 0.5242 - val_loss: 0.6769 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.55125 to 0.58750, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.6857 - accuracy: 0.5558 - val_loss: 0.6722 - val_accuracy: 0.5838\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.58750\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.6897 - accuracy: 0.5617 - val_loss: 0.6840 - val_accuracy: 0.5437\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.58750\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.6804 - accuracy: 0.5771 - val_loss: 0.6654 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.58750 to 0.62000, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntf.keras.applications.MobileNet(\\n    input_shape=(200,200,3),\\n    alpha=1.0,\\n    depth_multiplier=1,\\n    dropout=0.001,\\n    include_top=True,\\n    weights=\"imagenet\",\\n    input_tensor=None,\\n    pooling=None,\\n    classes=1000,\\n    classifier_activation=\"softmax\",\\n    **kwargs\\n)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint =  ModelCheckpoint('resnet50.h', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)    \n",
    "x_train_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_train))\n",
    "x_val_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_val))\n",
    "x_test_res=tf.keras.applications.resnet50.preprocess_input(np.copy(x_test))\n",
    "model = ResNet50(input_shape=(x_size,y_size,3),weights=None,include_top=False) ## Colocar otro top\n",
    "for i in range(165):\n",
    "    model.layers[i].trainable=False\n",
    "#model.summary()\n",
    "sal=model.output\n",
    "sal=Flatten()(sal)\n",
    "sal=Dense(502,activation='selu')(sal)\n",
    "sal=Dropout(0.26)(sal)\n",
    "sal = Dense(256, activation='relu')(sal)\n",
    "sal=Dense(100,activation='selu')(sal)\n",
    "sal=Dense(50,activation='relu')(sal)\n",
    "sal = Dense(2, activation='softmax')(sal)\n",
    "#Se unen la CNN y el top\n",
    "resnet50_custom=Model(inputs=model.input, outputs=sal)\n",
    "resnet50_custom.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "history=resnet50_custom.fit(x_train_res,y_train,batch_size=64,epochs=10, validation_data=(x_val_res,y_val),callbacks=[lr_reduce,earlystopper,checkpoint])\n",
    "#model.summary()\n",
    "#preds=model.predict(x_comb)\n",
    "#model.add(tf.keras.layers.Flaten())\n",
    "\"\"\"\n",
    "tf.keras.applications.MobileNet(\n",
    "    input_shape=(200,200,3),\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    **kwargs\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e74a1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactitud de la prueba=  55.5 %\n"
     ]
    }
   ],
   "source": [
    "#preds2=np.argmax(preds,axis=1)\n",
    "## Sale 111\n",
    "pred=resnet50_custom.predict(x_test_res)\n",
    "pred=np.argmax(pred,axis=1)\n",
    "y1=np.argmax(y_test,axis=1)\n",
    "\n",
    "#label=np.argmax(yp_oh)\n",
    "exactitud_test=0\n",
    "for a in range(len(pred)):\n",
    "    if pred[a]==y1[a]:\n",
    "        exactitud_test+=1\n",
    "print('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466acc1e",
   "metadata": {},
   "source": [
    "# EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd3d174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 114s 3s/step - loss: 0.7817 - accuracy: 0.5121 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldoa\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "38/38 [==============================] - 108s 3s/step - loss: 0.7432 - accuracy: 0.5217 - val_loss: 0.7003 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 106s 3s/step - loss: 0.7194 - accuracy: 0.5454 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 103s 3s/step - loss: 0.7187 - accuracy: 0.5354 - val_loss: 0.7034 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.50000\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 106s 3s/step - loss: 0.7089 - accuracy: 0.5279 - val_loss: 0.7149 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.50000\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 113s 3s/step - loss: 0.7175 - accuracy: 0.5312 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.50000\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 111s 3s/step - loss: 0.7047 - accuracy: 0.5417 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.50000\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 113s 3s/step - loss: 0.6963 - accuracy: 0.5500 - val_loss: 0.7104 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.50000\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 122s 3s/step - loss: 0.6931 - accuracy: 0.5567 - val_loss: 0.7237 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.50000\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 117s 3s/step - loss: 0.6919 - accuracy: 0.5462 - val_loss: 0.7225 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.50000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "#from tensorflow.keras.applications.efficientnet.EfficientNetB0 import EfficientNetB0\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint =  ModelCheckpoint('resnet50.h', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)    \n",
    "\n",
    "x_train_res=tf.keras.applications.efficientnet.preprocess_input(np.copy(x_train))\n",
    "x_val_res=tf.keras.applications.efficientnet.preprocess_input(np.copy(x_val))\n",
    "x_test_res=tf.keras.applications.efficientnet.preprocess_input(np.copy(x_test))\n",
    "\n",
    "model = tf.keras.applications.efficientnet.EfficientNetB0(input_shape=(x_size,y_size,3),weights=None,include_top=False) ## Colocar otro top\n",
    "#model.summary()\n",
    "sal=model.output\n",
    "sal=Flatten()(sal)\n",
    "sal=Dense(502,activation='relu')(sal)\n",
    "sal=Dropout(0.26)(sal)\n",
    "sal = Dense(256, activation='selu')(sal)\n",
    "sal=Dense(100,activation='selu')(sal)\n",
    "sal=Dense(50,activation='relu')(sal)\n",
    "sal = Dense(2, activation='softmax')(sal)\n",
    "#Se unen la CNN y el top\n",
    "efnetb0_custom=Model(inputs=model.input, outputs=sal)\n",
    "efnetb0_custom.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "history=efnetb0_custom.fit(x_train_res,y_train,batch_size=64,epochs=10, validation_data=(x_val_res,y_val),callbacks=[lr_reduce,earlystopper,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4cb2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactitud de la prueba=  50.0 %\n"
     ]
    }
   ],
   "source": [
    "pred=efnetb0_custom.predict(x_test_res)\n",
    "pred=np.argmax(pred,axis=1)\n",
    "y1=np.argmax(y_test,axis=1)\n",
    "\n",
    "#label=np.argmax(yp_oh)\n",
    "exactitud_test=0\n",
    "for a in range(len(pred)):\n",
    "    if pred[a]==y1[a]:\n",
    "        exactitud_test+=1\n",
    "print('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaefaeb",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fb7cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 66s 2s/step - loss: 0.7774 - accuracy: 0.4929 - val_loss: 0.6936 - val_accuracy: 0.4613\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46125, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.7294 - accuracy: 0.5183 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.46125 to 0.50000, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.7275 - accuracy: 0.5083 - val_loss: 0.6953 - val_accuracy: 0.4712\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.7169 - accuracy: 0.5146 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.51250, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.7096 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.51250 to 0.52000, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.7122 - accuracy: 0.5029 - val_loss: 0.6966 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.52000\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 59s 2s/step - loss: 0.7072 - accuracy: 0.5138 - val_loss: 0.6998 - val_accuracy: 0.4900\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.52000\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 61s 2s/step - loss: 0.7111 - accuracy: 0.5129 - val_loss: 0.6946 - val_accuracy: 0.5213\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.52000 to 0.52125, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.7062 - accuracy: 0.5133 - val_loss: 0.6957 - val_accuracy: 0.5387\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.52125 to 0.53875, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 60s 2s/step - loss: 0.6973 - accuracy: 0.5425 - val_loss: 0.7054 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.53875 to 0.56750, saving model to resnet50.h\n",
      "INFO:tensorflow:Assets written to: resnet50.h\\assets\n"
     ]
    }
   ],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint =  ModelCheckpoint('resnet50.h', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)    \n",
    "\n",
    "x_train_res=tf.keras.applications.inception_v3.preprocess_input(np.copy(x_train))\n",
    "x_val_res=tf.keras.applications.inception_v3.preprocess_input(np.copy(x_val))\n",
    "x_test_res=tf.keras.applications.inception_v3.preprocess_input(np.copy(x_test))\n",
    "\n",
    "model = tf.keras.applications.InceptionV3(input_shape=(x_size,y_size,3),weights=None,include_top=False) ## Colocar otro top\n",
    "#model.summary()\n",
    "sal=model.output\n",
    "sal=Flatten()(sal)\n",
    "sal=Dense(502,activation='relu')(sal)\n",
    "sal=Dropout(0.26)(sal)\n",
    "sal = Dense(256, activation='selu')(sal)\n",
    "sal=Dense(100,activation='selu')(sal)\n",
    "sal=Dense(50,activation='relu')(sal)\n",
    "sal = Dense(2, activation='softmax')(sal)\n",
    "#Se unen la CNN y el top\n",
    "incv3_custom=Model(inputs=model.input, outputs=sal)\n",
    "incv3_custom.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "history=incv3_custom.fit(x_train_res,y_train,batch_size=64,epochs=10, validation_data=(x_val_res,y_val),callbacks=[lr_reduce,earlystopper,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "946cd97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exactitud de la prueba=  47.5 %\n"
     ]
    }
   ],
   "source": [
    "pred=incv3_custom.predict(x_test_res)\n",
    "pred=np.argmax(pred,axis=1)\n",
    "y1=np.argmax(y_test,axis=1)\n",
    "\n",
    "#label=np.argmax(yp_oh)\n",
    "exactitud_test=0\n",
    "for a in range(len(pred)):\n",
    "    if pred[a]==y1[a]:\n",
    "        exactitud_test+=1\n",
    "print('exactitud de la prueba= ',100*exactitud_test/len(pred),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
